{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import numpy as np\n",
    "#from pyESN import ESN\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This cell contains PyESN\n",
    "# ADJUSTED FOR BRAM AKASH DMITRII (BAD) 17 nov 2017\n",
    "\n",
    "def threshold(pred, t_acc, t_brak):\n",
    "    # a BAD function\n",
    "    if len(pred.shape)>1:    \n",
    "        for i in range(len(pred[:,0])):\n",
    "            if pred[i,0] > t_acc:\n",
    "                pred[i,0] = 1\n",
    "            else:\n",
    "                pred[i,0] = 0\n",
    "        for i in range(len(pred[:,1])):\n",
    "            if pred[i,1] > t_brak:\n",
    "                pred[i,1] = 1\n",
    "            else:\n",
    "                pred[i,1] = 0\n",
    "    else:\n",
    "        if pred[0] > t_acc:\n",
    "            pred[0] = 1\n",
    "        else:\n",
    "            pred[0] = 0\n",
    "        if pred[1] > t_brak:\n",
    "            pred[1] = 1\n",
    "        else:\n",
    "            pred[1] = 0\n",
    "    return pred\n",
    "\n",
    "def correct_dimensions(s, targetlength):\n",
    "    \"\"\"checks the dimensionality of some numeric argument s, broadcasts it\n",
    "       to the specified length if possible.\n",
    "\n",
    "    Args:\n",
    "        s: None, scalar or 1D array\n",
    "        targetlength: expected length of s\n",
    "\n",
    "    Returns:\n",
    "        None if s is None, else numpy vector of length targetlength\n",
    "    \"\"\"\n",
    "    if s is not None:\n",
    "        s = np.array(s)\n",
    "        if s.ndim == 0:\n",
    "            s = np.array([s] * targetlength)\n",
    "        elif s.ndim == 1:\n",
    "            if not len(s) == targetlength:\n",
    "                raise ValueError(\"arg must have length \" + str(targetlength))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid argument\")\n",
    "    return s\n",
    "\n",
    "\n",
    "class ESN():\n",
    "\n",
    "    def __init__(self, n_inputs, n_outputs, n_reservoir=200,\n",
    "                 spectral_radius=0.95, sparsity=0, noise=0.001, input_shift=None,\n",
    "                 input_scaling=None, teacher_forcing=True, feedback_scaling=None,\n",
    "                 teacher_scaling=None, teacher_shift=None,\n",
    "                 out_activation=lambda x: x, inverse_out_activation=lambda x: x,\n",
    "                 random_state=None, silent=True, BAD=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_inputs: nr of input dimensions\n",
    "            n_outputs: nr of output dimensions\n",
    "            n_reservoir: nr of reservoir neurons\n",
    "            spectral_radius: spectral radius of the recurrent weight matrix\n",
    "            sparsity: proportion of recurrent weights set to zero\n",
    "            noise: noise added to each neuron (regularization)\n",
    "            input_shift: scalar or vector of length n_inputs to add to each\n",
    "                        input dimension before feeding it to the network.\n",
    "            input_scaling: scalar or vector of length n_inputs to multiply\n",
    "                        with each input dimension before feeding it to the netw.\n",
    "            teacher_forcing: if True, feed the target back into output units\n",
    "            teacher_scaling: factor applied to the target signal\n",
    "            teacher_shift: additive term applied to the target signal\n",
    "            out_activation: output activation function (applied to the readout)\n",
    "            inverse_out_activation: inverse of the output activation function\n",
    "            random_state: positive integer seed, np.rand.RandomState object,\n",
    "                          or None to use numpy's builting RandomState.\n",
    "            silent: supress messages\n",
    "            BAD: adjustments made by Bram Akash Dmitrii 17-11-2017 in order to experiment with PyESN for TORCS\n",
    "        \"\"\"\n",
    "        # check for proper dimensionality of all arguments and write them down.\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_reservoir = n_reservoir\n",
    "        self.n_outputs = n_outputs\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.sparsity = sparsity\n",
    "        self.noise = noise\n",
    "        self.input_shift = correct_dimensions(input_shift, n_inputs)\n",
    "        self.input_scaling = correct_dimensions(input_scaling, n_inputs)\n",
    "\n",
    "        self.teacher_scaling = teacher_scaling\n",
    "        self.teacher_shift = teacher_shift\n",
    "\n",
    "        self.out_activation = out_activation\n",
    "        self.inverse_out_activation = inverse_out_activation\n",
    "        self.random_state = random_state\n",
    "        self.BAD = BAD\n",
    "\n",
    "        # the given random_state might be either an actual RandomState object,\n",
    "        # a seed or None (in which case we use numpy's builtin RandomState)\n",
    "        if isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state_ = random_state\n",
    "        elif random_state:\n",
    "            try:\n",
    "                self.random_state_ = np.random.RandomState(random_state)\n",
    "            except TypeError as e:\n",
    "                raise Exception(\"Invalid seed: \" + str(e))\n",
    "        else:\n",
    "            self.random_state_ = np.random.mtrand._rand\n",
    "\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.silent = silent\n",
    "        self.initweights()\n",
    "        \n",
    "        if self.BAD:\n",
    "            self.t_acc = self.BAD[0]\n",
    "            self.t_brak = self.BAD[1]\n",
    "\n",
    "    def initweights(self):\n",
    "        # initialize recurrent weights:\n",
    "        # begin with a random matrix centered around zero:\n",
    "        W = self.random_state_.rand(self.n_reservoir, self.n_reservoir) - 0.5\n",
    "        # delete the fraction of connections given by (self.sparsity):\n",
    "        W[self.random_state_.rand(*W.shape) < self.sparsity] = 0\n",
    "        # compute the spectral radius of these weights:\n",
    "        radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "        # rescale them to reach the requested spectral radius:\n",
    "        self.W = W * (self.spectral_radius / radius)\n",
    "\n",
    "        # random input weights:\n",
    "        self.W_in = self.random_state_.rand(\n",
    "            self.n_reservoir, self.n_inputs) * 2 - 1\n",
    "        # random feedback (teacher forcing) weights:\n",
    "        self.W_feedb = self.random_state_.rand(\n",
    "            self.n_reservoir, self.n_outputs) * 2 - 1\n",
    "\n",
    "    def _update(self, state, input_pattern, output_pattern):\n",
    "        \"\"\"performs one update step.\n",
    "\n",
    "        i.e., computes the next network state by applying the recurrent weights\n",
    "        to the last state & and feeding in the current input and output patterns\n",
    "        \"\"\"\n",
    "        if self.teacher_forcing:\n",
    "            preactivation = (np.dot(self.W, state)\n",
    "                             + np.dot(self.W_in, input_pattern)\n",
    "                             + np.dot(self.W_feedb, output_pattern))\n",
    "        else:\n",
    "            preactivation = (np.dot(self.W, state)\n",
    "                             + np.dot(self.W_in, input_pattern))\n",
    "        \n",
    "        return (np.tanh(preactivation)\n",
    "                + self.noise * (self.random_state_.rand(self.n_reservoir) - 0.5))\n",
    "\n",
    "    def _scale_inputs(self, inputs):\n",
    "        \"\"\"for each input dimension j: multiplies by the j'th entry in the\n",
    "        input_scaling argument, then adds the j'th entry of the input_shift\n",
    "        argument.\"\"\"\n",
    "        if self.input_scaling is not None:\n",
    "            inputs = np.dot(inputs, np.diag(self.input_scaling))\n",
    "        if self.input_shift is not None:\n",
    "            inputs = inputs + self.input_shift\n",
    "        return inputs\n",
    "\n",
    "    def _scale_teacher(self, teacher):\n",
    "        \"\"\"multiplies the teacher/target signal by the teacher_scaling argument,\n",
    "        then adds the teacher_shift argument to it.\"\"\"\n",
    "        if self.teacher_scaling is not None:\n",
    "            teacher = teacher * self.teacher_scaling\n",
    "        if self.teacher_shift is not None:\n",
    "            teacher = teacher + self.teacher_shift\n",
    "        return teacher\n",
    "\n",
    "    def _unscale_teacher(self, teacher_scaled):\n",
    "        \"\"\"inverse operation of the _scale_teacher method.\"\"\"\n",
    "        if self.teacher_shift is not None:\n",
    "            teacher_scaled = teacher_scaled - self.teacher_shift\n",
    "        if self.teacher_scaling is not None:\n",
    "            teacher_scaled = teacher_scaled / self.teacher_scaling\n",
    "        return teacher_scaled\n",
    "\n",
    "    def fit(self, inputs, outputs, inspect=False):\n",
    "        \"\"\"\n",
    "        Collect the network's reaction to training data, train readout weights.\n",
    "\n",
    "        Args:\n",
    "            inputs: array of dimensions (N_training_samples x n_inputs)\n",
    "            outputs: array of dimension (N_training_samples x n_outputs)\n",
    "            inspect: show a visualisation of the collected reservoir states\n",
    "\n",
    "        Returns:\n",
    "            the network's output on the training data, using the trained weights\n",
    "        \"\"\"\n",
    "        # transform any vectors of shape (x,) into vectors of shape (x,1):\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        if outputs.ndim < 2:\n",
    "            outputs = np.reshape(outputs, (len(outputs), -1))\n",
    "        # transform input and teacher signal:\n",
    "        inputs_scaled = self._scale_inputs(inputs)\n",
    "        teachers_scaled = self._scale_teacher(outputs)\n",
    "\n",
    "        if not self.silent:\n",
    "            print(\"harvesting states...\")\n",
    "        # step the reservoir through the given input,output pairs:\n",
    "        states = np.zeros((inputs.shape[0], self.n_reservoir))\n",
    "        for n in range(1, inputs.shape[0]):\n",
    "            states[n, :] = self._update(states[n - 1], inputs_scaled[n, :],\n",
    "                                        teachers_scaled[n - 1, :])\n",
    "\n",
    "        # learn the weights, i.e. find the linear combination of collected\n",
    "        # network states that is closest to the target output\n",
    "        if not self.silent:\n",
    "            print(\"fitting...\")\n",
    "        # we'll disregard the first few states:\n",
    "        transient = min(int(inputs.shape[1] / 10), 100)\n",
    "        # include the raw inputs:\n",
    "        extended_states = np.hstack((states, inputs_scaled))\n",
    "        # Solve for W_out:\n",
    "        self.W_out = np.dot(np.linalg.pinv(extended_states[transient:, :]),\n",
    "                            self.inverse_out_activation(teachers_scaled[transient:, :])).T\n",
    "\n",
    "        # remember the last state for later:\n",
    "        self.laststate = states[-1, :]\n",
    "        self.lastinput = inputs[-1, :]\n",
    "        self.lastoutput = teachers_scaled[-1, :]\n",
    "\n",
    "        # optionally visualize the collected states\n",
    "        if inspect:\n",
    "            from matplotlib import pyplot as plt\n",
    "            # (^-- we depend on matplotlib only if this option is used)\n",
    "            plt.figure(\n",
    "                figsize=(states.shape[0] * 0.0025, states.shape[1] * 0.01))\n",
    "            plt.imshow(extended_states.T, aspect='auto',\n",
    "                       interpolation='nearest')\n",
    "            plt.colorbar()\n",
    "\n",
    "        if not self.silent:\n",
    "            print(\"training error:\")\n",
    "        # apply learned weights to the collected states:\n",
    "        pred_train = self._unscale_teacher(self.out_activation(\n",
    "            np.dot(extended_states, self.W_out.T)))\n",
    "        \n",
    "        if self.BAD:\n",
    "            pred_train = threshold(pred_train, self.t_acc, self.t_brak)\n",
    "        \n",
    "        if not self.silent:\n",
    "            print(np.sqrt(np.mean((pred_train - outputs)**2)))\n",
    "        return pred_train\n",
    "    \n",
    "    def predict(self, inputs, continuation=True):\n",
    "        \"\"\"\n",
    "        Apply the learned weights to the network's reactions to new input.\n",
    "\n",
    "        Args:\n",
    "            inputs: array of dimensions (N_test_samples x n_inputs)\n",
    "            continuation: if True, start the network from the last training state\n",
    "\n",
    "        Returns:\n",
    "            Array of output activations\n",
    "        \"\"\"\n",
    "        if inputs.ndim < 2:\n",
    "            inputs = np.reshape(inputs, (len(inputs), -1))\n",
    "        n_samples = inputs.shape[0]\n",
    "\n",
    "        if continuation:\n",
    "            laststate = self.laststate\n",
    "            lastinput = self.lastinput\n",
    "            lastoutput = self.lastoutput\n",
    "        else:\n",
    "            laststate = np.zeros(self.n_reservoir)\n",
    "            lastinput = np.zeros(self.n_inputs)\n",
    "            lastoutput = np.zeros(self.n_outputs)\n",
    "\n",
    "        inputs = np.vstack([lastinput, self._scale_inputs(inputs)])\n",
    "        states = np.vstack(\n",
    "            [laststate, np.zeros((n_samples, self.n_reservoir))])\n",
    "        outputs = np.vstack(\n",
    "            [lastoutput, np.zeros((n_samples, self.n_outputs))])\n",
    "\n",
    "        for n in range(n_samples):\n",
    "            states[\n",
    "                n + 1, :] = self._update(states[n, :], inputs[n + 1, :], outputs[n, :])\n",
    "            outputs[n + 1, :] = self.out_activation(np.dot(self.W_out,\n",
    "                                                           np.concatenate([states[n + 1, :], inputs[n + 1, :]])))\n",
    "            if self.BAD:\n",
    "                outputs[n+1,:] = threshold(outputs[n+1,:], self.t_acc, self.t_brak)\n",
    "                # one BAD rule says that if there is both braking and acceleration, braking has privilege\n",
    "                if outputs[n+1, 1] == 1:\n",
    "                    outputs[n+1, 0] = 0\n",
    "\n",
    "        return self._unscale_teacher(self.out_activation(outputs[1:]))       \n",
    "    \n",
    "    def race(self, sens_vec, prev_control, state):        \n",
    "        \"\"\"\n",
    "        BAD adjustment; racing for TORCS\n",
    "\n",
    "        pre-condition; the network has been trained\n",
    "\n",
    "        the fit() method takes the whole timeseries as input and gives a whole timeseries as output\n",
    "        we would like to give one timepoint as input and receive an output\n",
    "        at the next stage, it should still remember previous outputs in determining its new output \n",
    "\n",
    "        self; a trained ESN\n",
    "        sens_vec; a 22d vector of sensor data\n",
    "        prev_control; the previous commands the racer gave as control\n",
    "        state; the reservoir and its values\n",
    "        output; a 3d BAD vector of control commands\n",
    "        \"\"\"\n",
    "\n",
    "        state = self._update(state, sens_vec, prev_control)\n",
    "        controls = self.out_activation(np.dot(self.W_out, np.concatenate([state, sens_vec])))\n",
    "\n",
    "        if self.BAD:\n",
    "            controls = threshold(controls, self.t_acc, self.t_brak)\n",
    "            # one BAD rule says that if there is both braking and acceleration, braking has privilege\n",
    "            if controls[0] == 1:\n",
    "                controls[1] = 0\n",
    "\n",
    "        return controls, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some insight on the data\n",
    "\n",
    "def squash(a):\n",
    "    a = 0.49*a/max(a) # squash to values between 0.01 and 0.99\n",
    "    a = a + .5\n",
    "    return a\n",
    "\n",
    "def print_range(a):\n",
    "    print(\"min\", np.min(a))\n",
    "    print(\"avg\", np.mean(a))\n",
    "    print(\"max\", np.max(a))\n",
    "    \n",
    "def prep_data_for_esn(data, targets):\n",
    "    # adds a bias term to training data\n",
    "    # squashes the domain of the training data between 0 and 1 (excluding 0 and 1)\n",
    "    for d in data: \n",
    "        d.append(1.0) # add bias term\n",
    "    data = np.asarray(data)\n",
    "    for i in range( len(data[0]) - 1 ): # do not squash bias\n",
    "        data[:, i] = squash(data[:,i])\n",
    "        \n",
    "    targets = np.asarray(targets)   \n",
    "    return split_data(data, targets)\n",
    "\n",
    "def split_data(data, targets):\n",
    "    n_data = len(data)\n",
    "\n",
    "    n_train = int((len(data) * 0.6))\n",
    "    n_cv = int((len(data) * 0.2))\n",
    "    n_test = n_data - n_cv - n_train\n",
    "    \n",
    "    # data is not shuffled, because it is supposed to be sequential\n",
    "    \n",
    "    train_data = data[:n_train] \n",
    "    train_targets = targets[:n_train]\n",
    "\n",
    "    cv_data = data[n_train:n_train+n_cv]\n",
    "    cv_targets = targets[n_train:n_train+n_cv]\n",
    "    \n",
    "    test_data = data[n_train+n_cv:]\n",
    "    test_targets = targets[n_train+n_cv:]\n",
    "        \n",
    "    return [train_data[:,:], train_targets[:,:]], [cv_data[:,:], cv_targets[:,:]], [test_data[:,:], test_targets[:,:]]\n",
    "    \n",
    "# read in the data\n",
    "spd_data, spd_targets = preprocess.read_dataset(path=\"/home/bram/Documents/CI/ruimte-auto/data/f-speedway.csv\")\n",
    "alp_data, alp_targets = preprocess.read_dataset(path=\"/home/bram/Documents/CI/ruimte-auto/data/alpine-1.csv\")\n",
    "aal_data, aal_targets = preprocess.read_dataset(path=\"/home/bram/Documents/CI/ruimte-auto/data/aalborg.csv\")\n",
    "\n",
    "# data = np.asarray(data)\n",
    "# targets = np.asarray(targets)\n",
    "\n",
    "# get some insight on the data\n",
    "\n",
    "# print(\"data\")\n",
    "# for i in range(len(data[0])):\n",
    "#     plt.hist(data[:,i])\n",
    "#     plt.show()\n",
    "\n",
    "# print(\"targets\")\n",
    "# print(\"\")\n",
    "# for i in range(len(targets[0])):\n",
    "#     if i == 0: \n",
    "#         print(\"acceleration\")\n",
    "#     if i == 1: \n",
    "#         print(\"brake\")\n",
    "#     if i == 2: \n",
    "#         print(\"steering\")\n",
    "#     print_range(targets[:,i])\n",
    "#     plt.hist(targets[:,i])\n",
    "#     plt.show()\n",
    "\n",
    "# x = np.linspace(1, len(targets), len(targets))\n",
    "# plt.plot(x, targets[:,0], 'bx')\n",
    "# plt.show()\n",
    "# plt.plot(x, targets[:,1], 'rx')\n",
    "# plt.show()\n",
    "\n",
    "## it can be seen that there is almost always maximum acceleration\n",
    "## at the moments there is is braking, there is no acceleration\n",
    "## this confirms the intuition that you either brake or hit the gas\n",
    "\n",
    "spd_train, spd_cv, spd_test = prep_data_for_esn(spd_data, spd_targets)\n",
    "alp_train, alp_cv, alp_test = prep_data_for_esn(alp_data, alp_targets)\n",
    "aal_train, aal_cv, aal_test = prep_data_for_esn(aal_data, aal_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'train-error', 'test-error']\n",
      "['speedway', 0.013528978776407541, 0.010138456775490769]\n",
      "['aalborg', 0.20847499624475702, 0.99864700270221296]\n",
      "['alpine', 0.19232299972205857, 0.36852225979568698]\n"
     ]
    }
   ],
   "source": [
    "# let's see how dry unoptimized ESN performs on the data\n",
    "\n",
    "def compare_test_output(pred, target):\n",
    "    x = np.linspace(1,len(pred),len(pred))\n",
    "    print(\"\")\n",
    "    if len(pred[0]) == 1:\n",
    "        plt.plot(x, target, 'b-', alpha=.5)\n",
    "        plt.plot(x, pred, 'r-', alpha=.5)\n",
    "        #plt.ylim(-.2, 1.2)\n",
    "        plt.show()\n",
    "    else:\n",
    "        for i in range(len(pred[0])):        \n",
    "            if i == 0: \n",
    "                print(\"acceleration\")\n",
    "            if i == 1: \n",
    "                print(\"brake\")\n",
    "            if i == 2: \n",
    "                print(\"steering\")\n",
    "            plt.plot(x, target[:,i], 'bo', alpha=.1)\n",
    "            plt.plot(x, pred[:,i], 'ro', alpha=.1)\n",
    "            plt.ylim(-1.2, 1.2)\n",
    "            plt.show()\n",
    "            \n",
    "def train_test(esn, train_data, test_data): # could be used for test or CV\n",
    "    train_dat = train_data[0]\n",
    "    train_targ = train_data[1]\n",
    "    test_dat = test_data[0]\n",
    "    test_targ = test_data[1]\n",
    "    train_pred = esn.fit(train_dat, train_targ)\n",
    "    train_err = np.sqrt(np.mean((train_pred - train_targ)**2))\n",
    "    test_pred = esn.predict(test_dat)\n",
    "    test_err = np.sqrt(np.mean((test_pred - test_targ)**2))\n",
    "    return train_err, test_err \n",
    "\n",
    "rng = np.random.RandomState(42)        \n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = 0.5,\n",
    "          sparsity = 0.5,\n",
    "          noise = 0.1,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          #teacher_shift = -.7,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = False)\n",
    "\n",
    "# TO DO output this as a table\n",
    "table = []\n",
    "table.append([\"track\", \"train-error\", \"test-error\"])\n",
    "spd_train_err, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "table.append([\"speedway\", spd_train_err, spd_cv_err])\n",
    "aal_train_err, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "table.append([\"aalborg\", aal_train_err, aal_cv_err])\n",
    "alp_train_err, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "table.append([\"alpine\", alp_train_err, alp_cv_err])\n",
    "for row in table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'train-error', 'cv-error']\n",
      "['speedway', 0.013219660211200385, 0.010290026492711527]\n",
      "['aalborg', 0.23760113312755682, 0.4605088534502414]\n",
      "['alpine', 0.21569185064421267, 0.38655144794117247]\n"
     ]
    }
   ],
   "source": [
    "# it does not perform well\n",
    "# we add a 'classifier' to the acceleration and the brake\n",
    "# if the value is above the threshold, it will be one\n",
    "# if it is below, it is zero\n",
    "# you either brake, or you don't, in racing there is no place for insecurities\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = 0.5,\n",
    "          sparsity = 0.5,\n",
    "          noise = 0.1,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          #teacher_shift = -.7,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = [.5, .5])\n",
    "\n",
    "table = []\n",
    "table.append([\"track\", \"train-error\", \"cv-error\"])\n",
    "spd_train_err, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "table.append([\"speedway\", spd_train_err, spd_cv_err])\n",
    "aal_train_err, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "table.append([\"aalborg\", aal_train_err, aal_cv_err])\n",
    "alp_train_err, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "table.append([\"alpine\", alp_train_err, alp_cv_err])\n",
    "for row in table:\n",
    "    print(row)\n",
    "\n",
    "# the training error increases or decreases little\n",
    "# the cross-validation error increases a little\n",
    "# but for the aalborg track, the cross-validation error decreases a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TAKES A REALLY LONG TIME\n",
    "\n",
    "# we can try to improve performance by tweaking the hyperparameters\n",
    "# first we optimize hyperparameters on the situation without thresholding\n",
    "# spectral radius \n",
    "# sparsity\n",
    "# noise\n",
    "# teacher_shift\n",
    "skip = True\n",
    "if not skip:\n",
    "    cv_min = 1\n",
    "    for i in range(10):\n",
    "        spec_rad = 0.1*i\n",
    "        for j in range(10):\n",
    "            spars = j*0.1\n",
    "            for k in range(7):\n",
    "                noise_params = [.5, .4, .3, .2, .1, .05, .01]\n",
    "                nos = noise_params[k]\n",
    "                for l in range(10):\n",
    "                    tsh = .2*l - 1 # from 1 to -1 in 10 steps\n",
    "\n",
    "                    print(int(l+10*k+70*j+700*i),\"/7000\", end=\"\\r\")\n",
    "\n",
    "                    esn = ESN(n_inputs = 22,\n",
    "                          n_outputs = 3,\n",
    "                          n_reservoir = 200,\n",
    "                          spectral_radius = spec_rad,\n",
    "                          sparsity = spars,\n",
    "                          noise = nos,\n",
    "                          #input_shift = [0,0],\n",
    "                          #input_scaling = [0.01, 3],\n",
    "                          #teacher_scaling = .8,\n",
    "                          teacher_shift = tsh,\n",
    "                          #out_activation = np.tanh,\n",
    "                          #inverse_out_activation = np.arctanh,\n",
    "                          teacher_forcing = True,\n",
    "                          random_state = rng,\n",
    "                          silent = True,\n",
    "                          BAD = False)\n",
    "\n",
    "                    _, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "                    _, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "                    _, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "\n",
    "                    cv_err = np.mean([spd_cv_err, aal_cv_err, alp_cv_err])\n",
    "\n",
    "                    if cv_err < cv_min:\n",
    "                        best_param = [spec_rad, spars, nos, tsh]\n",
    "                        cv_min = cv_err\n",
    "\n",
    "    print( \"the best parameters are: \")\n",
    "    print( best_param )\n",
    "    print( \"with a cross-validation error of: \")\n",
    "    print( cv_min )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The threshold for the tresholding function was set to .5, but this can be better\n",
    "# we visually inspect the cross-validation data and estimate what treshold might be best\n",
    "# in the estimated region we try out hyperparameters in a similar fashion as above\n",
    "\n",
    "best_param = [.7, .4, .1, .2]\n",
    "\n",
    "spec_rad = best_param[0]\n",
    "spars = best_param[0]\n",
    "nos = best_param[0]\n",
    "tsh = best_param[0]\n",
    "\n",
    "if not skip:\n",
    "    esn = ESN(n_inputs = 22,\n",
    "              n_outputs = 3,\n",
    "              n_reservoir = 200,\n",
    "              spectral_radius = spec_rad,\n",
    "              sparsity = spars,\n",
    "              noise = nos,\n",
    "              #input_shift = [0,0],\n",
    "              #input_scaling = [0.01, 3],\n",
    "              #teacher_scaling = .8,\n",
    "              teacher_shift = tsh,\n",
    "              #out_activation = np.tanh,\n",
    "              #inverse_out_activation = np.arctanh,\n",
    "              teacher_forcing = True,\n",
    "              random_state = rng,\n",
    "              silent = True,\n",
    "              BAD = False)\n",
    "\n",
    "    print(\"red tries to imitate blue\")\n",
    "    print(\"speedway\")\n",
    "    spd_train_pred = esn.fit(spd_train[0], spd_train[1])\n",
    "    spd_cv_pred = esn.predict(spd_cv[0])\n",
    "    print(\"training\")\n",
    "    compare_test_output(spd_train_pred, spd_train[1])\n",
    "    print(\"cross-validation\")\n",
    "    compare_test_output(spd_cv_pred, spd_cv[1])\n",
    "\n",
    "    print(\"aalborg track\")\n",
    "    aal_train_pred = esn.fit(aal_train[0], aal_train[1])\n",
    "    aal_cv_pred = esn.predict(aal_cv[0])\n",
    "    print(\"training\")\n",
    "    compare_test_output(aal_train_pred, aal_train[1])\n",
    "    print(\"cross-validation\")\n",
    "    compare_test_output(aal_cv_pred, aal_cv[1])\n",
    "\n",
    "    print(\"alpine track\")\n",
    "    alp_train_pred = esn.fit(alp_train[0], alp_train[1])\n",
    "    alp_cv_pred = esn.predict(alp_cv[0])\n",
    "    print(\"training\")\n",
    "    compare_test_output(alp_train_pred, alp_train[1])\n",
    "    print(\"cross-validation\")\n",
    "    compare_test_output(alp_cv_pred, alp_cv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find that we do not brake often enough, and that we accelerate too often\n",
    "# we adjust the parameters\n",
    "# consider it as \"if you think you might have to brake, brake\" \n",
    "# \"if you're not completely sure you have to accelerate, don't\"\n",
    "\n",
    "if not skip:\n",
    "    cv_min = 1\n",
    "    for i in range(9):\n",
    "        t_acc = .5 + .05*i\n",
    "        for j in range(9):\n",
    "            print(i*9+j,\"/81\", end=\"\\r\")\n",
    "            t_brak = .05 + .05*j\n",
    "            esn = ESN(n_inputs = 22,\n",
    "                      n_outputs = 3,\n",
    "                      n_reservoir = 200,\n",
    "                      spectral_radius = spec_rad,\n",
    "                      sparsity = spars,\n",
    "                      noise = nos,\n",
    "                      #input_shift = [0,0],\n",
    "                      #input_scaling = [0.01, 3],\n",
    "                      #teacher_scaling = .8,\n",
    "                      teacher_shift = tsh,\n",
    "                      #out_activation = np.tanh,\n",
    "                      #inverse_out_activation = np.arctanh,\n",
    "                      teacher_forcing = True,\n",
    "                      random_state = rng,\n",
    "                      silent = True,\n",
    "                      BAD = [t_acc, t_brak] )\n",
    "\n",
    "            _, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "            _, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "            _, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "\n",
    "            cv_err = np.mean([spd_cv_err, aal_cv_err, alp_cv_err])\n",
    "\n",
    "            if cv_err < cv_min:\n",
    "                best_t = [t_acc, t_brak]\n",
    "                cv_min = cv_err\n",
    "        print(\"done\", end=\"\\r\")\n",
    "\n",
    "    print(\"the best choices for thresholding are:\")\n",
    "    print(best_t)\n",
    "    print(\"with a cross-validation of\")\n",
    "    print(cv_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_err', 'speedway', 'aalborg', 'alpine']\n",
      "['without BAD', 0.01411117782432986, 0.32655747671184726, 0.27841210521019255]\n",
      "['BAD', 0.99677542084891146, 0.95168421533989289, 0.95305412488671426]\n"
     ]
    }
   ],
   "source": [
    "# we gather the test error for ESN without and with BAD-adjustments\n",
    "\n",
    "best_t = [.85, .35]\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = spec_rad,\n",
    "          sparsity = spars,\n",
    "          noise = nos,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          teacher_shift = tsh,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = False )\n",
    "\n",
    "_, spd_test_err = train_test(esn, spd_train, spd_test)\n",
    "_, aal_test_err = train_test(esn, aal_train, aal_test)\n",
    "_, alp_test_err = train_test(esn, alp_train, alp_test)\n",
    "\n",
    "table = []\n",
    "table.append([\"test_err\", \"speedway\", \"aalborg\", \"alpine\"])\n",
    "table_row = []\n",
    "table_row.append(\"without BAD\")\n",
    "table_row.append(spd_test_err)\n",
    "table_row.append(aal_test_err)\n",
    "table_row.append(alp_test_err)\n",
    "table.append(table_row)\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = spec_rad,\n",
    "          sparsity = spars,\n",
    "          noise = nos,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          teacher_shift = tsh,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = best_t )\n",
    "\n",
    "\n",
    "_, spd_test_err = train_test(esn, spd_train, spd_test)\n",
    "_, aal_test_err = train_test(esn, aal_train, aal_test)\n",
    "_, alp_test_err = train_test(esn, alp_train, alp_test)\n",
    "\n",
    "table_row = []\n",
    "table_row.append(\"BAD\")\n",
    "table_row.append(spd_test_err)\n",
    "table_row.append(aal_test_err)\n",
    "table_row.append(alp_test_err)\n",
    "table.append(table_row)\n",
    "\n",
    "for row in table:\n",
    "    print(row)\n",
    "\n",
    "# going by test-error alone, BAD-improvements seem a BAD idea (pun intended)\n",
    "# we'll still check the behaviour in game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is used to test the race-function developed for BAD intentions\n",
    "\n",
    "best_param = [.7, .4, .1, .2]\n",
    "\n",
    "spec_rad = best_param[0]\n",
    "spars = best_param[0]\n",
    "nos = best_param[0]\n",
    "tsh = best_param[0]\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = spec_rad,\n",
    "          sparsity = spars,\n",
    "          noise = nos,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          teacher_shift = tsh,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = best_t )\n",
    "\n",
    "n_reservoir = 200\n",
    "state = np.zeros(n_reservoir)\n",
    "control = np.zeros(3)\n",
    "\n",
    "all_train_data = list(spd_train[0])\n",
    "all_train_data.extend(list(aal_train[0]))\n",
    "all_train_data.extend(list(alp_train[0]))\n",
    "all_train_data = np.asarray(all_train_data)\n",
    "all_train_targ = list(spd_train[1])\n",
    "all_train_targ.extend(list(aal_train[1]))\n",
    "all_train_targ.extend(list(alp_train[1]))\n",
    "all_train_targ = np.asarray(all_train_targ)\n",
    "\n",
    "_ = esn.fit(all_train_data, all_train_targ)\n",
    "\n",
    "spd_test_sensordata = spd_test[0]\n",
    "for i in range(len(spd_test_sensordata)):\n",
    "    sens_vec = spd_test_sensordata[i,:]\n",
    "    control, state = esn.race(sens_vec, control, state)\n",
    "    #print(control)\n",
    "\n",
    "import dill as pickle\n",
    "# import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# sample usage\n",
    "save_object(esn, 'esn.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
