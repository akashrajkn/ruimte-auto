{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import numpy as np\n",
    "#from pyESN import ESN\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "#np.set_printoptions(threshold=np.nan)\n",
    "np.set_printoptions(threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some insight on the data\n",
    "\n",
    "def squash(a):\n",
    "    a = 0.49*a/max(a) # squash to values between 0.01 and 0.99\n",
    "    a = a + .5\n",
    "    return a\n",
    "\n",
    "def print_range(a):\n",
    "    print(\"min\", np.min(a))\n",
    "    print(\"avg\", np.mean(a))\n",
    "    print(\"max\", np.max(a))\n",
    "    \n",
    "def prep_data_for_esn(data, targets):\n",
    "    # adds a bias term to training data\n",
    "    # squashes the domain of the training data between 0 and 1 (excluding 0 and 1)\n",
    "    for d in data: \n",
    "        d.append(1.0) # add bias term\n",
    "    data = np.asarray(data)\n",
    "    for i in range( len(data[0]) - 1 ): # do not squash bias\n",
    "        data[:, i] = squash(data[:,i])\n",
    "        \n",
    "    targets = np.asarray(targets)   \n",
    "    return split_data(data, targets)\n",
    "\n",
    "def split_data(data, targets):\n",
    "    n_data = len(data)\n",
    "\n",
    "    n_train = int((len(data) * 0.6))\n",
    "    n_cv = int((len(data) * 0.2))\n",
    "    n_test = n_data - n_cv - n_train\n",
    "    \n",
    "    # data is not shuffled, because it is supposed to be sequential\n",
    "    \n",
    "    train_data = data[:n_train] \n",
    "    train_targets = targets[:n_train]\n",
    "\n",
    "    cv_data = data[n_train:n_train+n_cv]\n",
    "    cv_targets = targets[n_train:n_train+n_cv]\n",
    "    \n",
    "    test_data = data[n_train+n_cv:]\n",
    "    test_targets = targets[n_train+n_cv:]\n",
    "        \n",
    "    return [train_data[:,:], train_targets[:,:]], [cv_data[:,:], cv_targets[:,:]], [test_data[:,:], test_targets[:,:]]\n",
    "    \n",
    "# read in the data\n",
    "spd_data, spd_targets = preprocess.read_dataset(path=\"/home/bram/Documents/CI/ruimte-auto/data/f-speedway.csv\")\n",
    "alp_data, alp_targets = preprocess.read_dataset(path=\"/home/bram/Documents/CI/ruimte-auto/data/alpine-1.csv\")\n",
    "aal_data, aal_targets = preprocess.read_dataset(path=\"/home/bram/Documents/CI/ruimte-auto/data/aalborg.csv\")\n",
    "\n",
    "# data = np.asarray(data)\n",
    "# targets = np.asarray(targets)\n",
    "\n",
    "# get some insight on the data\n",
    "\n",
    "# print(\"data\")\n",
    "# for i in range(len(data[0])):\n",
    "#     plt.hist(data[:,i])\n",
    "#     plt.show()\n",
    "\n",
    "# print(\"targets\")\n",
    "# print(\"\")\n",
    "# for i in range(len(targets[0])):\n",
    "#     if i == 0: \n",
    "#         print(\"acceleration\")\n",
    "#     if i == 1: \n",
    "#         print(\"brake\")\n",
    "#     if i == 2: \n",
    "#         print(\"steering\")\n",
    "#     print_range(targets[:,i])\n",
    "#     plt.hist(targets[:,i])\n",
    "#     plt.show()\n",
    "\n",
    "# x = np.linspace(1, len(targets), len(targets))\n",
    "# plt.plot(x, targets[:,0], 'bx')\n",
    "# plt.show()\n",
    "# plt.plot(x, targets[:,1], 'rx')\n",
    "# plt.show()\n",
    "\n",
    "## it can be seen that there is almost always maximum acceleration\n",
    "## at the moments there is is braking, there is no acceleration\n",
    "## this confirms the intuition that you either brake or hit the gas\n",
    "\n",
    "spd_train, spd_cv, spd_test = prep_data_for_esn(spd_data, spd_targets)\n",
    "alp_train, alp_cv, alp_test = prep_data_for_esn(alp_data, alp_targets)\n",
    "aal_train, aal_cv, aal_test = prep_data_for_esn(aal_data, aal_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'train-error', 'test-error']\n",
      "['speedway', 0.013528978776407541, 0.010138456775490769]\n",
      "['aalborg', 0.20847499624475702, 0.99864700270221296]\n",
      "['alpine', 0.19232299972205857, 0.36852225979568698]\n"
     ]
    }
   ],
   "source": [
    "# let's see how dry unoptimized ESN performs on the data\n",
    "\n",
    "def compare_test_output(pred, target):\n",
    "    x = np.linspace(1,len(pred),len(pred))\n",
    "    print(\"\")\n",
    "    if len(pred[0]) == 1:\n",
    "        plt.plot(x, target, 'b-', alpha=.5)\n",
    "        plt.plot(x, pred, 'r-', alpha=.5)\n",
    "        #plt.ylim(-.2, 1.2)\n",
    "        plt.show()\n",
    "    else:\n",
    "        for i in range(len(pred[0])):        \n",
    "            if i == 0: \n",
    "                print(\"acceleration\")\n",
    "            if i == 1: \n",
    "                print(\"brake\")\n",
    "            if i == 2: \n",
    "                print(\"steering\")\n",
    "            plt.plot(x, target[:,i], 'bo', alpha=.1)\n",
    "            plt.plot(x, pred[:,i], 'ro', alpha=.1)\n",
    "            plt.ylim(-1.2, 1.2)\n",
    "            plt.show()\n",
    "            \n",
    "def train_test(esn, train_data, test_data): # could be used for test or CV\n",
    "    train_dat = train_data[0]\n",
    "    train_targ = train_data[1]\n",
    "    test_dat = test_data[0]\n",
    "    test_targ = test_data[1]\n",
    "    train_pred = esn.fit(train_dat, train_targ)\n",
    "    train_err = np.sqrt(np.mean((train_pred - train_targ)**2))\n",
    "    test_pred = esn.predict(test_dat)\n",
    "    test_err = np.sqrt(np.mean((test_pred - test_targ)**2))\n",
    "    return train_err, test_err \n",
    "\n",
    "rng = np.random.RandomState(42)        \n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = 0.5,\n",
    "          sparsity = 0.5,\n",
    "          noise = 0.1,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          #teacher_shift = -.7,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = False)\n",
    "\n",
    "# TO DO output this as a table\n",
    "table = []\n",
    "table.append([\"track\", \"train-error\", \"test-error\"])\n",
    "spd_train_err, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "table.append([\"speedway\", spd_train_err, spd_cv_err])\n",
    "aal_train_err, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "table.append([\"aalborg\", aal_train_err, aal_cv_err])\n",
    "alp_train_err, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "table.append([\"alpine\", alp_train_err, alp_cv_err])\n",
    "for row in table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'train-error', 'cv-error']\n",
      "['speedway', 0.013219660211200385, 0.010290026492711527]\n",
      "['aalborg', 0.23760113312755682, 0.4605088534502414]\n",
      "['alpine', 0.21569185064421267, 0.38655144794117247]\n"
     ]
    }
   ],
   "source": [
    "# it does not perform well\n",
    "# we add a 'classifier' to the acceleration and the brake\n",
    "# if the value is above the threshold, it will be one\n",
    "# if it is below, it is zero\n",
    "# you either brake, or you don't, in racing there is no place for insecurities\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = 0.5,\n",
    "          sparsity = 0.5,\n",
    "          noise = 0.1,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          #teacher_shift = -.7,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = [.5, .5])\n",
    "\n",
    "table = []\n",
    "table.append([\"track\", \"train-error\", \"cv-error\"])\n",
    "spd_train_err, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "table.append([\"speedway\", spd_train_err, spd_cv_err])\n",
    "aal_train_err, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "table.append([\"aalborg\", aal_train_err, aal_cv_err])\n",
    "alp_train_err, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "table.append([\"alpine\", alp_train_err, alp_cv_err])\n",
    "for row in table:\n",
    "    print(row)\n",
    "\n",
    "# the training error increases or decreases little\n",
    "# the cross-validation error increases a little\n",
    "# but for the aalborg track, the cross-validation error decreases a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL TAKES A REALLY LONG TIME\n",
    "\n",
    "# we can try to improve performance by tweaking the hyperparameters\n",
    "# first we optimize hyperparameters on the situation without thresholding\n",
    "# spectral radius \n",
    "# sparsity\n",
    "# noise\n",
    "# teacher_shift\n",
    "skip = True\n",
    "if not skip:\n",
    "    cv_min = 1\n",
    "    for i in range(10):\n",
    "        spec_rad = 0.1*i\n",
    "        for j in range(10):\n",
    "            spars = j*0.1\n",
    "            for k in range(7):\n",
    "                noise_params = [.5, .4, .3, .2, .1, .05, .01]\n",
    "                nos = noise_params[k]\n",
    "                for l in range(10):\n",
    "                    tsh = .2*l - 1 # from 1 to -1 in 10 steps\n",
    "\n",
    "                    print(int(l+10*k+70*j+700*i),\"/7000\", end=\"\\r\")\n",
    "\n",
    "                    esn = ESN(n_inputs = 22,\n",
    "                          n_outputs = 3,\n",
    "                          n_reservoir = 200,\n",
    "                          spectral_radius = spec_rad,\n",
    "                          sparsity = spars,\n",
    "                          noise = nos,\n",
    "                          #input_shift = [0,0],\n",
    "                          #input_scaling = [0.01, 3],\n",
    "                          #teacher_scaling = .8,\n",
    "                          teacher_shift = tsh,\n",
    "                          #out_activation = np.tanh,\n",
    "                          #inverse_out_activation = np.arctanh,\n",
    "                          teacher_forcing = True,\n",
    "                          random_state = rng,\n",
    "                          silent = True,\n",
    "                          BAD = False)\n",
    "\n",
    "                    _, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "                    _, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "                    _, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "\n",
    "                    cv_err = np.mean([spd_cv_err, aal_cv_err, alp_cv_err])\n",
    "\n",
    "                    if cv_err < cv_min:\n",
    "                        best_param = [spec_rad, spars, nos, tsh]\n",
    "                        cv_min = cv_err\n",
    "\n",
    "    print( \"the best parameters are: \")\n",
    "    print( best_param )\n",
    "    print( \"with a cross-validation error of: \")\n",
    "    print( cv_min )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The threshold for the tresholding function was set to .5, but this can be better\n",
    "# we visually inspect the cross-validation data and estimate what treshold might be best\n",
    "# in the estimated region we try out hyperparameters in a similar fashion as above\n",
    "\n",
    "best_param = [.7, .4, .1, .2]\n",
    "\n",
    "spec_rad = best_param[0]\n",
    "spars = best_param[0]\n",
    "nos = best_param[0]\n",
    "tsh = best_param[0]\n",
    "\n",
    "if not skip:\n",
    "    esn = ESN(n_inputs = 22,\n",
    "              n_outputs = 3,\n",
    "              n_reservoir = 200,\n",
    "              spectral_radius = spec_rad,\n",
    "              sparsity = spars,\n",
    "              noise = nos,\n",
    "              #input_shift = [0,0],\n",
    "              #input_scaling = [0.01, 3],\n",
    "              #teacher_scaling = .8,\n",
    "              teacher_shift = tsh,\n",
    "              #out_activation = np.tanh,\n",
    "              #inverse_out_activation = np.arctanh,\n",
    "              teacher_forcing = True,\n",
    "              random_state = rng,\n",
    "              silent = True,\n",
    "              BAD = False)\n",
    "\n",
    "    print(\"red tries to imitate blue\")\n",
    "    print(\"speedway\")\n",
    "    spd_train_pred = esn.fit(spd_train[0], spd_train[1])\n",
    "    spd_cv_pred = esn.predict(spd_cv[0])\n",
    "    print(\"training\")\n",
    "    compare_test_output(spd_train_pred, spd_train[1])\n",
    "    print(\"cross-validation\")\n",
    "    compare_test_output(spd_cv_pred, spd_cv[1])\n",
    "\n",
    "    print(\"aalborg track\")\n",
    "    aal_train_pred = esn.fit(aal_train[0], aal_train[1])\n",
    "    aal_cv_pred = esn.predict(aal_cv[0])\n",
    "    print(\"training\")\n",
    "    compare_test_output(aal_train_pred, aal_train[1])\n",
    "    print(\"cross-validation\")\n",
    "    compare_test_output(aal_cv_pred, aal_cv[1])\n",
    "\n",
    "    print(\"alpine track\")\n",
    "    alp_train_pred = esn.fit(alp_train[0], alp_train[1])\n",
    "    alp_cv_pred = esn.predict(alp_cv[0])\n",
    "    print(\"training\")\n",
    "    compare_test_output(alp_train_pred, alp_train[1])\n",
    "    print(\"cross-validation\")\n",
    "    compare_test_output(alp_cv_pred, alp_cv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we find that we do not brake often enough, and that we accelerate too often\n",
    "# we adjust the parameters\n",
    "# consider it as \"if you think you might have to brake, brake\" \n",
    "# \"if you're not completely sure you have to accelerate, don't\"\n",
    "\n",
    "if not skip:\n",
    "    cv_min = 1\n",
    "    for i in range(9):\n",
    "        t_acc = .5 + .05*i\n",
    "        for j in range(9):\n",
    "            print(i*9+j,\"/81\", end=\"\\r\")\n",
    "            t_brak = .05 + .05*j\n",
    "            esn = ESN(n_inputs = 22,\n",
    "                      n_outputs = 3,\n",
    "                      n_reservoir = 200,\n",
    "                      spectral_radius = spec_rad,\n",
    "                      sparsity = spars,\n",
    "                      noise = nos,\n",
    "                      #input_shift = [0,0],\n",
    "                      #input_scaling = [0.01, 3],\n",
    "                      #teacher_scaling = .8,\n",
    "                      teacher_shift = tsh,\n",
    "                      #out_activation = np.tanh,\n",
    "                      #inverse_out_activation = np.arctanh,\n",
    "                      teacher_forcing = True,\n",
    "                      random_state = rng,\n",
    "                      silent = True,\n",
    "                      BAD = [t_acc, t_brak] )\n",
    "\n",
    "            _, spd_cv_err = train_test(esn, spd_train, spd_cv) \n",
    "            _, aal_cv_err = train_test(esn, aal_train, aal_cv) \n",
    "            _, alp_cv_err = train_test(esn, alp_train, alp_cv) \n",
    "\n",
    "            cv_err = np.mean([spd_cv_err, aal_cv_err, alp_cv_err])\n",
    "\n",
    "            if cv_err < cv_min:\n",
    "                best_t = [t_acc, t_brak]\n",
    "                cv_min = cv_err\n",
    "        print(\"done\", end=\"\\r\")\n",
    "\n",
    "    print(\"the best choices for thresholding are:\")\n",
    "    print(best_t)\n",
    "    print(\"with a cross-validation of\")\n",
    "    print(cv_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_err', 'speedway', 'aalborg', 'alpine']\n",
      "['without BAD', 0.01411117782432986, 0.32655747671184726, 0.27841210521019255]\n",
      "['BAD', 0.99677542084891146, 0.95168421533989289, 0.95305412488671426]\n"
     ]
    }
   ],
   "source": [
    "# we gather the test error for ESN without and with BAD-adjustments\n",
    "\n",
    "best_t = [.85, .35]\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = spec_rad,\n",
    "          sparsity = spars,\n",
    "          noise = nos,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          teacher_shift = tsh,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = False )\n",
    "\n",
    "_, spd_test_err = train_test(esn, spd_train, spd_test)\n",
    "_, aal_test_err = train_test(esn, aal_train, aal_test)\n",
    "_, alp_test_err = train_test(esn, alp_train, alp_test)\n",
    "\n",
    "table = []\n",
    "table.append([\"test_err\", \"speedway\", \"aalborg\", \"alpine\"])\n",
    "table_row = []\n",
    "table_row.append(\"without BAD\")\n",
    "table_row.append(spd_test_err)\n",
    "table_row.append(aal_test_err)\n",
    "table_row.append(alp_test_err)\n",
    "table.append(table_row)\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = spec_rad,\n",
    "          sparsity = spars,\n",
    "          noise = nos,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          teacher_shift = tsh,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = best_t )\n",
    "\n",
    "\n",
    "_, spd_test_err = train_test(esn, spd_train, spd_test)\n",
    "_, aal_test_err = train_test(esn, aal_train, aal_test)\n",
    "_, alp_test_err = train_test(esn, alp_train, alp_test)\n",
    "\n",
    "table_row = []\n",
    "table_row.append(\"BAD\")\n",
    "table_row.append(spd_test_err)\n",
    "table_row.append(aal_test_err)\n",
    "table_row.append(alp_test_err)\n",
    "table.append(table_row)\n",
    "\n",
    "for row in table:\n",
    "    print(row)\n",
    "\n",
    "# going by test-error alone, BAD-improvements seem a BAD idea (pun intended)\n",
    "# we'll still check the behaviour in game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this cell is used to test the race-function developed for BAD intentions\n",
    "\n",
    "best_param = [.7, .4, .1, .2]\n",
    "\n",
    "spec_rad = best_param[0]\n",
    "spars = best_param[0]\n",
    "nos = best_param[0]\n",
    "tsh = best_param[0]\n",
    "\n",
    "esn = ESN(n_inputs = 22,\n",
    "          n_outputs = 3,\n",
    "          n_reservoir = 200,\n",
    "          spectral_radius = spec_rad,\n",
    "          sparsity = spars,\n",
    "          noise = nos,\n",
    "          #input_shift = [0,0],\n",
    "          #input_scaling = [0.01, 3],\n",
    "          #teacher_scaling = .8,\n",
    "          teacher_shift = tsh,\n",
    "          #out_activation = np.tanh,\n",
    "          #inverse_out_activation = np.arctanh,\n",
    "          teacher_forcing = True,\n",
    "          random_state = rng,\n",
    "          silent = True,\n",
    "          BAD = best_t )\n",
    "\n",
    "n_reservoir = 200\n",
    "state = np.zeros(n_reservoir)\n",
    "control = np.zeros(3)\n",
    "\n",
    "all_train_data = list(spd_train[0])\n",
    "all_train_data.extend(list(aal_train[0]))\n",
    "all_train_data.extend(list(alp_train[0]))\n",
    "all_train_data = np.asarray(all_train_data)\n",
    "all_train_targ = list(spd_train[1])\n",
    "all_train_targ.extend(list(aal_train[1]))\n",
    "all_train_targ.extend(list(alp_train[1]))\n",
    "all_train_targ = np.asarray(all_train_targ)\n",
    "\n",
    "_ = esn.fit(all_train_data, all_train_targ)\n",
    "\n",
    "spd_test_sensordata = spd_test[0]\n",
    "for i in range(len(spd_test_sensordata)):\n",
    "    sens_vec = spd_test_sensordata[i,:]\n",
    "    control, state = esn.race(sens_vec, control, state)\n",
    "    #print(control)\n",
    "\n",
    "import dill as pickle\n",
    "# import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# sample usage\n",
    "save_object(esn, 'esn.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
